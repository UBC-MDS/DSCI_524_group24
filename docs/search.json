[
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "RidgeMake Tutorial",
    "section": "",
    "text": "This guide provides a functional overview of a four-step workflow for performing linear regression, evaluating model performance, and visualizing results using NumPy and Matplotlib.\n\n\n\n\n\n\n\n\nFunction\nPurpose\nKey Mechanism\n\n\n\n\nget_reg_line\nFit & Predict\nUses the Normal Equation to calculate optimal weights and return predictions.\n\n\nridge_get_r2\nEvaluate\nComputes the R2 score to measure the proportion of variance captured by the model.\n\n\nridge_scatter\nVisualize (Data)\nPlots the raw observations (x,y) onto a Matplotlib Axes object.\n\n\nridge_scatter_line\nVisualize (Model)\nOverlays the predicted regression line onto the existing scatter plot."
  },
  {
    "objectID": "tutorial.html#ridgemake-workflow-tutorial",
    "href": "tutorial.html#ridgemake-workflow-tutorial",
    "title": "RidgeMake Tutorial",
    "section": "",
    "text": "This guide provides a functional overview of a four-step workflow for performing linear regression, evaluating model performance, and visualizing results using NumPy and Matplotlib.\n\n\n\n\n\n\n\n\nFunction\nPurpose\nKey Mechanism\n\n\n\n\nget_reg_line\nFit & Predict\nUses the Normal Equation to calculate optimal weights and return predictions.\n\n\nridge_get_r2\nEvaluate\nComputes the R2 score to measure the proportion of variance captured by the model.\n\n\nridge_scatter\nVisualize (Data)\nPlots the raw observations (x,y) onto a Matplotlib Axes object.\n\n\nridge_scatter_line\nVisualize (Model)\nOverlays the predicted regression line onto the existing scatter plot."
  },
  {
    "objectID": "tutorial.html#implementataion-example",
    "href": "tutorial.html#implementataion-example",
    "title": "RidgeMake Tutorial",
    "section": "Implementataion Example",
    "text": "Implementataion Example\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ridge_remake.get_reg_line import get_reg_line\nfrom ridge_remake.ridge_r2 import ridge_get_r2\nfrom ridge_scatter_line import ridge_scatter_line\nfrom ridge_scatter import ridge_scatter\n\n# 1. Generate Synthetic Data\nnp.random.seed(42)\nX = 2 * np.random.rand(50, 1)\ny = 4 + 3 * X + np.random.randn(50, 1) # y = 4 + 3x + noise\n\n# 2. Compute Predictions\n# get_reg_line handles the bias term internally via the Normal Equation\ny_pred = get_reg_line(X, y)\n\n# 3. Calculate Model Accuracy\nr2_score = ridge_get_r2(y, y_pred)\nprint(f\"Model R² Score: {r2_score:.4f}\")\n\n# 4. Visualization\nfig, ax = plt.subplots(figsize=(8, 5))\n\n# Plot raw data\nridge_scatter(ax, X, y, label=\"Observed Data\", scatter_kwargs={\"color\": \"blue\", \"alpha\": 0.6})\n\n# Plot regression line\nridge_scatter_line(ax, X, y_pred, label=f\"Regression Line (R²={r2_score:.2f})\", \n                   line_kwargs={\"color\": \"red\", \"linewidth\": 2})\n\nax.set_xlabel(\"Independent Variable (X)\")\nax.set_ylabel(\"Target (y)\")\nax.set_title(\"Simple Linear Regression Fit\")\nax.legend()\nplt.show()"
  },
  {
    "objectID": "tutorial.html#key-technical-considerations",
    "href": "tutorial.html#key-technical-considerations",
    "title": "RidgeMake Tutorial",
    "section": "Key Technical Considerations",
    "text": "Key Technical Considerations\nMatrix Operations: get_reg_line relies on np.linalg.inv. Note that for high-dimensional data or collinear features, the matrix XTX may be singular (non-invertible).\nThe Bias Term: The prediction function automatically prepends a column of ones to the input matrix. This ensures the model accounts for the intercept (β0​), preventing the line from being forced through the origin.\nSorting for Plots: ridge_scatter_line includes a sort_x=True parameter. This is critical when working with shuffled data; without it, Matplotlib connects points in their index order, resulting in a “zig-zag” mess rather than a clean line.\nR2 Interpretation:\n\n1.0: Perfect fit.\n0.0: Model predicts no better than the mean of y.\nNegative: The model is worse than simply predicting the mean (usually indicates a non-linear trend or severe overfit on training data)."
  }
]